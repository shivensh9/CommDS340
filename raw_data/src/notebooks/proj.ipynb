{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m20yY4WVox3r",
        "outputId": "a25d6e9e-fc03-4ab9-b91a-a22f01d08cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  CommDS340.zip\n",
            "   creating: DS340Project/CommDS340/\n",
            "  inflating: DS340Project/__MACOSX/._CommDS340  \n",
            "  inflating: DS340Project/CommDS340/.DS_Store  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/._.DS_Store  \n",
            " extracting: DS340Project/CommDS340/requirements.txt  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/._requirements.txt  \n",
            "   creating: DS340Project/CommDS340/raw_data/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/._raw_data  \n",
            " extracting: DS340Project/CommDS340/README.md  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/._README.md  \n",
            "   creating: DS340Project/CommDS340/.git/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/._.git  \n",
            " extracting: DS340Project/CommDS340/main.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/._main.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/.DS_Store  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/._.DS_Store  \n",
            "   creating: DS340Project/CommDS340/raw_data/data/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/._data  \n",
            "   creating: DS340Project/CommDS340/raw_data/src/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/._src  \n",
            "  inflating: DS340Project/CommDS340/.git/.DS_Store  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._.DS_Store  \n",
            "  inflating: DS340Project/CommDS340/.git/ORIG_HEAD  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._ORIG_HEAD  \n",
            "  inflating: DS340Project/CommDS340/.git/config  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._config  \n",
            "   creating: DS340Project/CommDS340/.git/objects/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._objects  \n",
            "  inflating: DS340Project/CommDS340/.git/HEAD  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._HEAD  \n",
            "   creating: DS340Project/CommDS340/.git/info/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._info  \n",
            "   creating: DS340Project/CommDS340/.git/logs/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._logs  \n",
            "  inflating: DS340Project/CommDS340/.git/description  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._description  \n",
            "   creating: DS340Project/CommDS340/.git/hooks/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._hooks  \n",
            "   creating: DS340Project/CommDS340/.git/refs/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._refs  \n",
            "  inflating: DS340Project/CommDS340/.git/index  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._index  \n",
            "  inflating: DS340Project/CommDS340/.git/COMMIT_EDITMSG  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._COMMIT_EDITMSG  \n",
            "  inflating: DS340Project/CommDS340/.git/FETCH_HEAD  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/._FETCH_HEAD  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/.DS_Store  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/._.DS_Store  \n",
            "   creating: DS340Project/CommDS340/raw_data/data/processed/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/._processed  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/.DS_Store  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/._.DS_Store  \n",
            "   creating: DS340Project/CommDS340/raw_data/src/preprocess/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/._preprocess  \n",
            "   creating: DS340Project/CommDS340/raw_data/src/prompt_engineering/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/._prompt_engineering  \n",
            "   creating: DS340Project/CommDS340/raw_data/src/model/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/._model  \n",
            "   creating: DS340Project/CommDS340/raw_data/src/notebooks/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/._notebooks  \n",
            "   creating: DS340Project/CommDS340/.git/objects/61/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._61  \n",
            "   creating: DS340Project/CommDS340/.git/objects/95/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._95  \n",
            "   creating: DS340Project/CommDS340/.git/objects/9b/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._9b  \n",
            "   creating: DS340Project/CommDS340/.git/objects/9e/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._9e  \n",
            "   creating: DS340Project/CommDS340/.git/objects/56/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._56  \n",
            "   creating: DS340Project/CommDS340/.git/objects/58/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._58  \n",
            "   creating: DS340Project/CommDS340/.git/objects/93/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._93  \n",
            "   creating: DS340Project/CommDS340/.git/objects/0e/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._0e  \n",
            "   creating: DS340Project/CommDS340/.git/objects/5a/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._5a  \n",
            "   creating: DS340Project/CommDS340/.git/objects/02/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._02  \n",
            "   creating: DS340Project/CommDS340/.git/objects/a3/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._a3  \n",
            "   creating: DS340Project/CommDS340/.git/objects/ad/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._ad  \n",
            "   creating: DS340Project/CommDS340/.git/objects/d8/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._d8  \n",
            "   creating: DS340Project/CommDS340/.git/objects/f5/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._f5  \n",
            "   creating: DS340Project/CommDS340/.git/objects/e3/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._e3  \n",
            "   creating: DS340Project/CommDS340/.git/objects/cf/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._cf  \n",
            "   creating: DS340Project/CommDS340/.git/objects/fb/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._fb  \n",
            "   creating: DS340Project/CommDS340/.git/objects/20/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._20  \n",
            "   creating: DS340Project/CommDS340/.git/objects/4b/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._4b  \n",
            "   creating: DS340Project/CommDS340/.git/objects/pack/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._pack  \n",
            "   creating: DS340Project/CommDS340/.git/objects/7c/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._7c  \n",
            "   creating: DS340Project/CommDS340/.git/objects/16/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._16  \n",
            "   creating: DS340Project/CommDS340/.git/objects/89/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._89  \n",
            "   creating: DS340Project/CommDS340/.git/objects/45/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._45  \n",
            "   creating: DS340Project/CommDS340/.git/objects/74/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._74  \n",
            "   creating: DS340Project/CommDS340/.git/objects/7b/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._7b  \n",
            "   creating: DS340Project/CommDS340/.git/objects/8f/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._8f  \n",
            "   creating: DS340Project/CommDS340/.git/objects/7e/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._7e  \n",
            "   creating: DS340Project/CommDS340/.git/objects/21/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._21  \n",
            "   creating: DS340Project/CommDS340/.git/objects/4d/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._4d  \n",
            "   creating: DS340Project/CommDS340/.git/objects/81/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._81  \n",
            "   creating: DS340Project/CommDS340/.git/objects/86/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._86  \n",
            "   creating: DS340Project/CommDS340/.git/objects/44/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._44  \n",
            "   creating: DS340Project/CommDS340/.git/objects/2a/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._2a  \n",
            "   creating: DS340Project/CommDS340/.git/objects/6b/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._6b  \n",
            "   creating: DS340Project/CommDS340/.git/objects/31/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._31  \n",
            "   creating: DS340Project/CommDS340/.git/objects/info/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._info  \n",
            "   creating: DS340Project/CommDS340/.git/objects/62/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._62  \n",
            "   creating: DS340Project/CommDS340/.git/objects/53/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._53  \n",
            "   creating: DS340Project/CommDS340/.git/objects/01/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._01  \n",
            "   creating: DS340Project/CommDS340/.git/objects/6c/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._6c  \n",
            "   creating: DS340Project/CommDS340/.git/objects/99/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._99  \n",
            "   creating: DS340Project/CommDS340/.git/objects/0f/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._0f  \n",
            "   creating: DS340Project/CommDS340/.git/objects/0a/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._0a  \n",
            "   creating: DS340Project/CommDS340/.git/objects/d3/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._d3  \n",
            "   creating: DS340Project/CommDS340/.git/objects/b8/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._b8  \n",
            "   creating: DS340Project/CommDS340/.git/objects/b1/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._b1  \n",
            "   creating: DS340Project/CommDS340/.git/objects/d2/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._d2  \n",
            "   creating: DS340Project/CommDS340/.git/objects/aa/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._aa  \n",
            "   creating: DS340Project/CommDS340/.git/objects/ef/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._ef  \n",
            "   creating: DS340Project/CommDS340/.git/objects/e1/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._e1  \n",
            "   creating: DS340Project/CommDS340/.git/objects/cc/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._cc  \n",
            "   creating: DS340Project/CommDS340/.git/objects/e6/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._e6  \n",
            "   creating: DS340Project/CommDS340/.git/objects/f1/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._f1  \n",
            "   creating: DS340Project/CommDS340/.git/objects/ce/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._ce  \n",
            "   creating: DS340Project/CommDS340/.git/objects/e0/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._e0  \n",
            "   creating: DS340Project/CommDS340/.git/objects/2d/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._2d  \n",
            "   creating: DS340Project/CommDS340/.git/objects/41/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._41  \n",
            "   creating: DS340Project/CommDS340/.git/objects/83/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._83  \n",
            "   creating: DS340Project/CommDS340/.git/objects/85/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._85  \n",
            "   creating: DS340Project/CommDS340/.git/objects/49/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._49  \n",
            "   creating: DS340Project/CommDS340/.git/objects/2b/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/._2b  \n",
            "  inflating: DS340Project/CommDS340/.git/info/exclude  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/info/._exclude  \n",
            "  inflating: DS340Project/CommDS340/.git/logs/HEAD  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/._HEAD  \n",
            "   creating: DS340Project/CommDS340/.git/logs/refs/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/._refs  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/commit-msg.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._commit-msg.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/pre-rebase.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._pre-rebase.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/pre-commit.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._pre-commit.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._applypatch-msg.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._fsmonitor-watchman.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/pre-receive.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._pre-receive.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._prepare-commit-msg.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/post-update.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._post-update.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._pre-merge-commit.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._pre-applypatch.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/pre-push.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._pre-push.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/update.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._update.sample  \n",
            "  inflating: DS340Project/CommDS340/.git/hooks/push-to-checkout.sample  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/hooks/._push-to-checkout.sample  \n",
            "   creating: DS340Project/CommDS340/.git/refs/heads/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/refs/._heads  \n",
            "   creating: DS340Project/CommDS340/.git/refs/tags/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/refs/._tags  \n",
            "   creating: DS340Project/CommDS340/.git/refs/remotes/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/refs/._remotes  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/processed/.DS_Store  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/processed/._.DS_Store  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/processed/last_81k_draft.jsonl  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/processed/._last_81k_draft.jsonl  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/processed/tuning_dataset.jsonl  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/processed/._tuning_dataset.jsonl  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/processed/all_draft_commentary.jsonl  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/processed/._all_draft_commentary.jsonl  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/processed/last_81k_enhance.jsonl  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/processed/._last_81k_enhance.jsonl  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/processed/all_enhanced.jsonl  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/processed/._all_enhanced.jsonl  \n",
            "  inflating: DS340Project/CommDS340/raw_data/data/processed/draft_commentary.jsonl  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/data/processed/._draft_commentary.jsonl  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/preprocess/align_events.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/preprocess/._align_events.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/preprocess/NBA_PBP_2020-21.csv  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/preprocess/._NBA_PBP_2020-21.csv  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/preprocess/convert_to_hf_format.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/preprocess/._convert_to_hf_format.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/preprocess/clean_play_by_play.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/preprocess/._clean_play_by_play.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/preprocess/generate_draft_commentary.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/preprocess/._generate_draft_commentary.py  \n",
            "   creating: DS340Project/CommDS340/raw_data/src/prompt_engineering/__pycache__/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/prompt_engineering/.___pycache__  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/prompt_engineering/templates.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/prompt_engineering/._templates.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/prompt_engineering/template_generator.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/prompt_engineering/._template_generator.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/model/fine_tune_converter.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/model/._fine_tune_converter.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/model/train_hf_t5.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/model/._train_hf_t5.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/model/config.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/model/._config.py  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/model/enhance_with_gpt.py  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/model/._enhance_with_gpt.py  \n",
            "   creating: DS340Project/CommDS340/raw_data/src/notebooks/configs/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/notebooks/._configs  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/61/fc2a1a5b4875d0ba44a564e8cd87b6fa43b1cf  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/61/._fc2a1a5b4875d0ba44a564e8cd87b6fa43b1cf  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/95/409ef6005b102f288a4f2c8edebb16852b87ae  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/95/._409ef6005b102f288a4f2c8edebb16852b87ae  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/9b/d440c8999c79607c75f5fba5a934158f557db9  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/9b/._d440c8999c79607c75f5fba5a934158f557db9  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/9e/4d3f331451c56e44d11d1ceb36260be130706b  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/9e/._4d3f331451c56e44d11d1ceb36260be130706b  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/9e/ae258d1eb6918fe00894e4e17b40ea3f42e3de  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/9e/._ae258d1eb6918fe00894e4e17b40ea3f42e3de  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/56/7d005bb0b92a57d1c86da84b547948f4e158da  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/56/._7d005bb0b92a57d1c86da84b547948f4e158da  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/58/8e8c0c856abbc248dd7bfa7e5b404f44c1d20f  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/58/._8e8c0c856abbc248dd7bfa7e5b404f44c1d20f  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/93/7cfbd799c093ad1131c89f9ded321b7b4c1a61  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/93/._7cfbd799c093ad1131c89f9ded321b7b4c1a61  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/0e/d7d53db3df88a4606b545568f2aaaf39020168  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/0e/._d7d53db3df88a4606b545568f2aaaf39020168  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/0e/c88356859f2b63f67caac7c6d13af1970ce48b  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/0e/._c88356859f2b63f67caac7c6d13af1970ce48b  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/5a/8e1b3a0831f0a348b298ad93a9369f07ded87f  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/5a/._8e1b3a0831f0a348b298ad93a9369f07ded87f  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/02/fef10a27d411ab6183c6de609b0abe5ef30df4  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/02/._fef10a27d411ab6183c6de609b0abe5ef30df4  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/02/fbf5d070fc631e8490f31490f3f795754ddbf2  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/02/._fbf5d070fc631e8490f31490f3f795754ddbf2  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/a3/61e2d78fc58f907b8f361fc84105be24a6b746  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/a3/._61e2d78fc58f907b8f361fc84105be24a6b746  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/ad/bb172b1d5a86b704ed6d2d8d7f45d47a51e264  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/ad/._bb172b1d5a86b704ed6d2d8d7f45d47a51e264  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/d8/4667fd504a35a59849a3d18eb67da807c1a21d  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/d8/._4667fd504a35a59849a3d18eb67da807c1a21d  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/f5/50c7fc0d0b32da03f9554356284207441af652  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/f5/._50c7fc0d0b32da03f9554356284207441af652  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/e3/4367e59cadf19646520eedca1bf9c5f48bb11a  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/e3/._4367e59cadf19646520eedca1bf9c5f48bb11a  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/cf/4bcc9e371f67a9f47ca30f9f099f22de8524d8  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/cf/._4bcc9e371f67a9f47ca30f9f099f22de8524d8  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/fb/6f73a0586f2a7c6ba15b481f05f7d2f2b9d8f1  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/fb/._6f73a0586f2a7c6ba15b481f05f7d2f2b9d8f1  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/fb/22a8b81bb2070d24526540c09c8a1cec6c1f91  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/fb/._22a8b81bb2070d24526540c09c8a1cec6c1f91  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/20/28c0d1a745bdc59ded5df1a9ac5142d3a8e8cc  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/20/._28c0d1a745bdc59ded5df1a9ac5142d3a8e8cc  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/4b/825dc642cb6eb9a060e54bf8d69288fbee4904  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/4b/._825dc642cb6eb9a060e54bf8d69288fbee4904  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/7c/fb548d09421c04f509f1edf013e4ceb5b255f0  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/7c/._fb548d09421c04f509f1edf013e4ceb5b255f0  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/16/300519c9691b9116413bbe1acbdb6d28f482d2  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/16/._300519c9691b9116413bbe1acbdb6d28f482d2  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/89/8a04f23ce755857db69c22f81b8351c9aee7da  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/89/._8a04f23ce755857db69c22f81b8351c9aee7da  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/89/6afb0db74cae1b98d641713b2bf43ebed9d909  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/89/._6afb0db74cae1b98d641713b2bf43ebed9d909  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/89/102228eb6d567f233c2ed8108588b5e4e59a73  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/89/._102228eb6d567f233c2ed8108588b5e4e59a73  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/45/6b93005aee7ea278ecfb6a95e440316df6b912  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/45/._6b93005aee7ea278ecfb6a95e440316df6b912  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/45/6e866b4428692c1f7f0e3f1d2da23889cb0100  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/45/._6e866b4428692c1f7f0e3f1d2da23889cb0100  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/74/bc9bed67aff3ad60aab7e7bd0b67706f369ff3  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/74/._bc9bed67aff3ad60aab7e7bd0b67706f369ff3  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/7b/f806f3593565f5a8dcb1a60936a55799938a1b  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/7b/._f806f3593565f5a8dcb1a60936a55799938a1b  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/8f/7c79209b409e580706606ecca53763ef125c01  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/8f/._7c79209b409e580706606ecca53763ef125c01  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/7e/d5310887cbeecd796bb27bb9b1645e6f86b67e  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/7e/._d5310887cbeecd796bb27bb9b1645e6f86b67e  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/7e/2b8c0d62d063092914ea51030ff9d57304a795  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/7e/._2b8c0d62d063092914ea51030ff9d57304a795  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/21/6a9f8102b1e9f8e0e7ba3d1c583239a302ea70  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/21/._6a9f8102b1e9f8e0e7ba3d1c583239a302ea70  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/21/f60bd08714f48dac1ca45ef447ce78fa499721  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/21/._f60bd08714f48dac1ca45ef447ce78fa499721  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/4d/89c9c0874ae0a4182de3096b4114d842f72148  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/4d/._89c9c0874ae0a4182de3096b4114d842f72148  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/81/079e7db53d8f6d7175152d9a086e2d26b3513d  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/81/._079e7db53d8f6d7175152d9a086e2d26b3513d  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/86/e0230cd69afa9b37e12ef77b348b84289f02c8  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/86/._e0230cd69afa9b37e12ef77b348b84289f02c8  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/44/8d0d266fdd6980e135a1874158aa8cdfe7f973  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/44/._8d0d266fdd6980e135a1874158aa8cdfe7f973  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/2a/d260f2f1a8352d5584f3fec0134cc3186e9f8b  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/2a/._d260f2f1a8352d5584f3fec0134cc3186e9f8b  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/6b/e6f11c8c357f0ff59aace14e0466e85ce11a18  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/6b/._e6f11c8c357f0ff59aace14e0466e85ce11a18  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/31/9f43747b486f54547113e7020d3fa5ebc57fcb  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/31/._9f43747b486f54547113e7020d3fa5ebc57fcb  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/31/4277d8a958adc1365ca760c13792145290a0a2  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/31/._4277d8a958adc1365ca760c13792145290a0a2  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/62/d9b05b2740370c4c4ed239a9c67ed8dcf9b523  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/62/._d9b05b2740370c4c4ed239a9c67ed8dcf9b523  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/53/0a29c39c4e443c98d46d543470a99794a735c7  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/53/._0a29c39c4e443c98d46d543470a99794a735c7  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/53/f70b586e6c256a26d045fe8c6e7d7faf3b7fda  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/53/._f70b586e6c256a26d045fe8c6e7d7faf3b7fda  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/53/b94db6f217c78433058dad4566fb28ff54a2a5  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/53/._b94db6f217c78433058dad4566fb28ff54a2a5  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/01/cf2f0544f85fbd41786523e2d9601f958306c3  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/01/._cf2f0544f85fbd41786523e2d9601f958306c3  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/01/fb501d449b1d5df7f5fc73a3105e8754e238a7  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/01/._fb501d449b1d5df7f5fc73a3105e8754e238a7  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/6c/c61aab786ff10b0e9182ddffc4c3439d2c60a2  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/6c/._c61aab786ff10b0e9182ddffc4c3439d2c60a2  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/6c/7d0c0c8d95366b1af2446328f80238392ec457  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/6c/._7d0c0c8d95366b1af2446328f80238392ec457  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/99/6f33eb19ada64bba7a695bb0d18b2b8963c735  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/99/._6f33eb19ada64bba7a695bb0d18b2b8963c735  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/0f/0e1a9528b18ca100aa7afb3376b2a62f3b2397  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/0f/._0e1a9528b18ca100aa7afb3376b2a62f3b2397  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/0a/7a690d594a6a7c02f1d2521956e096c12b0a13  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/0a/._7a690d594a6a7c02f1d2521956e096c12b0a13  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/0a/279b0a1145dea7e8ffe6b12a124a95520fe540  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/0a/._279b0a1145dea7e8ffe6b12a124a95520fe540  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/d3/7d79054735f4267a9a9303fa199779b9268180  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/d3/._7d79054735f4267a9a9303fa199779b9268180  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/b8/21abeaf57f881b77bddf0304ae8781c4b34a0b  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/b8/._21abeaf57f881b77bddf0304ae8781c4b34a0b  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/b1/2b2a5382135a6dcdd2ac58445fb4ff1a6d3495  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/b1/._2b2a5382135a6dcdd2ac58445fb4ff1a6d3495  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/d2/4ce2f5420ba02739c213bdb3ad10db839140ed  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/d2/._4ce2f5420ba02739c213bdb3ad10db839140ed  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/d2/1e02120083b0bf0954bfc67d15763aa44613c5  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/d2/._1e02120083b0bf0954bfc67d15763aa44613c5  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/aa/69ec1435619f02643fa53117c7590b1851a7c3  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/aa/._69ec1435619f02643fa53117c7590b1851a7c3  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/ef/3d0f73e01cc33b0b0f9eec9fdc32d3d5b0a037  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/ef/._3d0f73e01cc33b0b0f9eec9fdc32d3d5b0a037  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/e1/9c246ae8b94ffc5cdb4facb5d6641c163f04cf  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/e1/._9c246ae8b94ffc5cdb4facb5d6641c163f04cf  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/cc/923c89b3ee0897a101ce78ee0d7741e0fdfe69  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/cc/._923c89b3ee0897a101ce78ee0d7741e0fdfe69  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/e6/6eb22e32b7cdebe5b8df028551d6109866c394  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/e6/._6eb22e32b7cdebe5b8df028551d6109866c394  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/e6/._9de29bb2d1d6434b8b29ae775ad8c2e48c5391  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/f1/cb4f32db9a31f3308625d6471c52b155052e30  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/f1/._cb4f32db9a31f3308625d6471c52b155052e30  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/ce/7df4fd12fa7ad2b46498cd20cb7c14bc1c5d9f  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/ce/._7df4fd12fa7ad2b46498cd20cb7c14bc1c5d9f  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/e0/3778eac06f0d3b8e9f21098732529a02395104  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/e0/._3778eac06f0d3b8e9f21098732529a02395104  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/2d/ff91d574c438501e2e80e1b0d6eba733b45bc0  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/2d/._ff91d574c438501e2e80e1b0d6eba733b45bc0  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/41/e1dc5df11e344236e9ea60acc8d0d0db3ab173  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/41/._e1dc5df11e344236e9ea60acc8d0d0db3ab173  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/83/66096a055f9c20a03025e613405ec67a9ba17f  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/83/._66096a055f9c20a03025e613405ec67a9ba17f  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/83/f393404931ec016ba4705228feede041c5b905  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/83/._f393404931ec016ba4705228feede041c5b905  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/85/2d495466d2c63af536876edeb25e5dbc434f37  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/85/._2d495466d2c63af536876edeb25e5dbc434f37  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/49/467ad7620e15dcc1f14af9d284671176d5eefd  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/49/._467ad7620e15dcc1f14af9d284671176d5eefd  \n",
            "  inflating: DS340Project/CommDS340/.git/objects/2b/d30fa7b5a94f6525995eaa3d141ea8b374fe1d  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/objects/2b/._d30fa7b5a94f6525995eaa3d141ea8b374fe1d  \n",
            "   creating: DS340Project/CommDS340/.git/logs/refs/heads/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/refs/._heads  \n",
            "   creating: DS340Project/CommDS340/.git/logs/refs/remotes/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/refs/._remotes  \n",
            "  inflating: DS340Project/CommDS340/.git/refs/heads/main  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/refs/heads/._main  \n",
            "   creating: DS340Project/CommDS340/.git/refs/remotes/origin/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/refs/remotes/._origin  \n",
            "  inflating: DS340Project/CommDS340/raw_data/src/prompt_engineering/__pycache__/template_generator.cpython-311.pyc  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/raw_data/src/prompt_engineering/__pycache__/._template_generator.cpython-311.pyc  \n",
            "  inflating: DS340Project/CommDS340/.git/logs/refs/heads/main  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/refs/heads/._main  \n",
            "   creating: DS340Project/CommDS340/.git/logs/refs/remotes/origin/\n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/refs/remotes/._origin  \n",
            "  inflating: DS340Project/CommDS340/.git/refs/remotes/origin/aryan-work  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/refs/remotes/origin/._aryan-work  \n",
            "  inflating: DS340Project/CommDS340/.git/refs/remotes/origin/main  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/refs/remotes/origin/._main  \n",
            "  inflating: DS340Project/CommDS340/.git/logs/refs/remotes/origin/aryan-work  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/refs/remotes/origin/._aryan-work  \n",
            "  inflating: DS340Project/CommDS340/.git/logs/refs/remotes/origin/main  \n",
            "  inflating: DS340Project/__MACOSX/CommDS340/.git/logs/refs/remotes/origin/._main  \n"
          ]
        }
      ],
      "source": [
        "!unzip CommDS340.zip -d DS340Project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ0LXoNFtTsq",
        "outputId": "cfbd73c9-51b8-4f9f-c828-418c985e366e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MNoXRx1tY4t",
        "outputId": "5b19953d-11d8-4a08-ebfc-52e1fcfcbd70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnODF-mKu8tU",
        "outputId": "2a6f8754-1283-40b7-a897-37de0f6f235e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft==0.10.0\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2025.1.31)\n",
            "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/DS340Project/CommDS340/raw_data/src/model/train_hf_t5.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mRT_pKAtheL",
        "outputId": "4f332ef4-2acd-48b5-cb3c-c674272407ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-23 00:30:02.392551: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745368202.411870    3207 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745368202.417902    3207 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-23 00:30:02.438185: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/content/DS340Project/CommDS340/raw_data/src/model/train_hf_t5.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "  0% 0/36060 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.23}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.84}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.89}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.96}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.99}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 3.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 3.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 3.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 3.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 3.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 3.0}\n",
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 3.0}\n",
            "{'train_runtime': 3782.6525, 'train_samples_per_second': 76.261, 'train_steps_per_second': 9.533, 'train_loss': 0.0, 'epoch': 3.0}\n",
            "100% 36060/36060 [1:03:02<00:00,  9.53it/s]\n",
            " Fine-tuning complete! Model saved to: t5_basketball_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyvhjX7fSpLO",
        "outputId": "b2e85238-b578-487d-d078-59657034a317"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip /content/t5_basketball_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZorzyJBSqlt",
        "outputId": "c2767d5d-59f4-4749-91de-4cb3f5609e64"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/t5_basketball_model/ (stored 0%)\n",
            "  adding: content/t5_basketball_model/model.safetensors (deflated 7%)\n",
            "  adding: content/t5_basketball_model/added_tokens.json (deflated 83%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/ (stored 0%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/optimizer.pt (deflated 46%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/model.safetensors (deflated 7%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/added_tokens.json (deflated 83%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/scaler.pt (deflated 60%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/tokenizer_config.json (deflated 94%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/special_tokens_map.json (deflated 85%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/trainer_state.json (deflated 94%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/config.json (deflated 62%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/scheduler.pt (deflated 57%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/generation_config.json (deflated 29%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/spiece.model (deflated 48%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/training_args.bin (deflated 52%)\n",
            "  adding: content/t5_basketball_model/checkpoint-36060/rng_state.pth (deflated 25%)\n",
            "  adding: content/t5_basketball_model/tokenizer_config.json (deflated 94%)\n",
            "  adding: content/t5_basketball_model/special_tokens_map.json (deflated 85%)\n",
            "  adding: content/t5_basketball_model/config.json (deflated 62%)\n",
            "  adding: content/t5_basketball_model/generation_config.json (deflated 29%)\n",
            "  adding: content/t5_basketball_model/spiece.model (deflated 48%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "69jOOi6gTTcB",
        "outputId": "0b58358a-f22f-40ec-a340-770cfac34185"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4eb6dbd-d52e-4715-8e47-36f6fbf3928a\", \"model.zip\", 571620126)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}